---
para: area
domain: 领域
type: 笔记
tags: [写作系统, 观点打磨]
status: active
summary: 根据原料得出的「升维结果」是：
created: 2026-02-13
updated: 2026-02-13
reviewed_at: 2026-02-14
---

# DeepMind刚刚证明：未来的AI，将由AI自己设计

---

**根据原料得出的「升维结果」是：**

原观点：DeepMind发了一篇论文，让AI自己发明学习算法，结果超过了人类设计的算法。

**升维路径选择：B（结构映射法） + A（时间延时法）**

原观点太战术（描述技术细节），需要上升到更高维度的系统思考：这不仅是一个技术突破，更标志着AI进化的「相变时刻」——从"人类设计算法给AI用"到"AI自己发明算法"。这代表着智能系统从「被优化」变成了「自优化」，AI获得了「设计AI」的能力。

拉长时间轴来看：过去几十年，人类一直是AI进步的「瓶颈」。现在DeepMind证明了：这个瓶颈可以被移除。这意味着AI的进化速度，可以脱离人类的认知带宽限制。

---

**「TakeAways」是：**

**视角锚**：以后当你再看到任何AI技术突破时，可以先问自己一个问题：「这次进步，是人类在教AI，还是AI在教AI？」如果是后者，那才是真正值得关注的拐点。

**记忆锚**：「人类设计的规则，被AI证明太低效了。」——这句话值得记住。

---

**选用的写作类型与目的是：**

**一、高维认知与趋势解读**

目的：立权威 & 破圈——表达"我懂趋势，我看得比别人远"，指明方向，让读者相信你看得远、看得准。

---

**选用的文章结构是：**

**SCQA结构（麦肯锡金字塔原理）**

- S（情境）：大家都知道AI很强，但AI怎么学习的？靠的是人类科学家设计的算法
- C（冲突）：有一天，AI自己设计的算法，超过了人类设计的
- Q（疑问）：这意味着什么？下一步会发生什么？
- A（答案）：AI正在获得「自我进化」的能力，人类将从「设计者」变成「观察者」

---

**使用的互动埋点策略（HEIP）：**

1. **颗粒度细化**：「把伸出被窝的那只脚又缩回去」→ 映射到「AI发明了一些没有名字的变量y和z」这个细节
2. **坎宁安陷阱**：抛出「再过几年，AI论文可能都不需要人类来写了」这个主观暴论，引发讨论
3. **结尾留白**：不做总结，而是问一个问题：「你觉得，我们离那一天还有多远？」

---

## 完整的文章是：

---

2025年10月22日，Nature发表了一篇DeepMind的论文。

通往下一代AI的路径，可能藏在这篇论文里

---

### 先说这篇论文做了什么

在强化学习领域，有一个核心问题：**AI该怎么从经验中学习？**

过去几十年，这个问题的答案都是：**由人类科学家来设计学习规则**。

人类发明的「学习公式」
你可以把它们理解为「老师给学生布置的学习方法」
撞墙就扣分，吃到金币就加分，按这个规则来调整自己的行为。

DeepMind这篇论文做的事情是：**让AI自己发明学习规则。**

![DiscoRL架构图 - 论文Fig.1，展示了AI如何自主发现强化学习规则](discorl_fig1.png)

具体怎么做的呢？

他们设计了两波AI。一波是「学生AI」，负责玩各种游戏；另一波是「老师AI」（Meta-network），专门观察学生AI的学习过程。

老师AI不玩游戏，它只做一件事：**找出什么样的「学习规则」能让学生AI学得更快更好**，然后不断改进这个规则。

经过成千上万次迭代，这套由AI自己发明的学习规则——被命名为**DiscoRL**——打破了Atari游戏测试的历史记录。

更关键的是，这套规则不仅在训练用的游戏上表现出色，拿去玩从来没见过的新游戏，它也比人类设计的算法更强。

**这才是真正炸裂的地方。**

---

### 为什么这件事很重要？

让我换一种方式说。

过去40年，AI进步的路径是这样的：

1. **第一阶段**：人类手把手教AI「看什么」（特征工程时代）。人类告诉AI：这是棋盘的好棋型，这是危险位置。AI能力的上限 = 人类能描述的知识的上限。

2. **第二阶段**：人类教AI「怎么学」，让它自己提取特征（深度学习时代）。人类不再告诉AI看哪里，但仍然规定学习规则：如果你赢了，就按这个公式加强刚才的动作。AI能力的上限 = 人类能设计的算法的上限。

3. **第三阶段（这篇论文）**：AI自己发明「怎么学」。

**人类从「直接操控」到「只管规则」，再到「连规则都管不了」。**

每一次进化的本质都是一样的：**人类往后退一步，AI往前进一步**。

这篇论文证明的，就是AI已经有能力承接「设计学习规则」这个权力了。

---

### 有一个细节，特别值得玩味

论文里提到，他们发现的这套算法使用了两组神秘的向量，叫做**y**和**z**。

这两个变量**没有预定义的含义**。

人类不知道它们代表什么。是代表危险？代表机会？代表价值？都不是。

它们不对应任何人类能理解的概念。

但实验证明，AI只要关注这些「莫名其妙」的指标，就能学得比只关注人类定义的「奖励」或「价值」更好。

**AI发明了自己的「心理语言」，而这套语言人类看不懂。**

这让我想到一个有点恐怖的可能：

> 未来最高效的智能形式，可能完全不符合人类的逻辑。我们只能看到它在解决问题，却永远无法理解它「在想什么」。

---

### 站远一点看：这意味着什么？

如果说AlphaGo的胜利是「在人类设计的规则里打败了人类」——

那这篇论文的胜利是「AI证明人类设计的规则太低效了，然后自己发明了更好的」。

这不是量变，是质变。

过去，AI的进步靠的是：DeepMind发论文 → 工程师读论文 → 改代码 → AI变强。

未来的路径可能是：AI做实验 → AI修改自己的底层代码 → AI变强。

**人类科学家不再是AI进化的「设计者」，变成了「观察者」**

论文的结尾写得非常直白：

> 「这表明，未来AI算法的设计，可能将由机器来主导，而机器能够利用数据和算力进行有效的扩展。」



**我们人类的认知带宽太窄了，还是让AI自己来吧。**

---

### 最后

这篇论文让我想到一句以前看过的话：

> 「真正的革命不会告诉你它来了，它只会让你发现：规则已经被改写了。」

现在的问题是：我们到底是在见证这个时刻，还是它早就开始了，而我们才刚反应过来？

---

如果以后你再看到任何AI突破的新闻，可以先问自己一个问题：

**「这次进步，是人类在教AI，还是AI在教AI？」**

如果是后者——那才是真正的拐点。

你觉得，我们离那一天还有多远？

评论区聊聊。

---

## 标题是：

**单标题系统：**

**公式一：颠覆认知型**（适合本文核心：反常识——人类设计的算法被AI设计的算法打败）

1. Nature刚刚发布：人类设计的AI算法，被AI自己设计的打败了
2. DeepMind最新论文：AI的学习规则，以后不用人类来设计了
3. 2024年最被低估的AI论文：AI已经学会「进化自己的进化方式」

**公式四：量化成果型**（用数据冲击 + 权威背书）

1. Nature论文证实：AI自己发明的算法，打破了Atari 40年的测试记录
2. DeepMind这篇论文，可能预示了AI下一个10年的进化路径
3. 连学习规则都由AI来设计了——这意味着什么？

---

**双标题系统：**

**观点暴论型**（封面拦路 + 标题指路）

| 封面文案              | 标题文案                            |
| ----------------- | ------------------------------- |
| **AI已经会进化自己了**    | Nature刚刚发布：人类设计的算法，被AI自己设计的打败了  |
| **人类的规则 太低效了**    | DeepMind证明：让AI设计AI的学习规则，比人类做得更好 |
| **下一个10年 AI自己进化** | 这篇Nature论文，可能是AI时代真正的「奇点信号」     |

**结果前置型**（数据冲击 + 技术颠覆）

| 封面文案 | 标题文案 |
|---------|---------|
| **Atari历史最高分 AI自己设计的算法打破的** | DeepMind的DiscoRL：第一个超越人类设计的AI学习规则 |
| **连规则都不用人类设计了** | Nature论文解读：AI正在获得「自我进化」的能力 |
| **40年的算法研究 被AI一次超越** | 这篇论文让我重新思考：未来AI论文还需要人类写吗？ |

---

> **参考来源**：
> - 论文地址：https://www.nature.com/articles/s41586-025-09761-x
> - deepmind项目地址：https://google-deepmind.github.io/disco_rl/
> - 代码开源地址：https://github.com/google-deepmind/disco_rl

