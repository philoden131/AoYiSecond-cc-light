---
para: area
domain: 领域
type: 笔记
tags: [写作系统, 观点打磨, 分发策略]
status: active
summary: 2025年10月22日，Nature发表了一篇DeepMind的论文。
created: 2026-02-13
updated: 2026-02-13
reviewed_at: 2026-02-14
---

2025年10月22日，Nature发表了一篇DeepMind的论文。

通往下一代AI的路径，可能藏在这篇论文里

先说这篇论文做了什么
在强化学习领域，有一个核心问题：AI该怎么从经验中学习？

过去几十年，这个问题的答案都是：由人类科学家来设计学习规则。

人类发明的「学习公式」
你可以把它们理解为「老师给学生布置的学习方法」
撞墙就扣分，吃到金币就加分，按这个规则来调整自己的行为。

DeepMind这篇论文做的事情是：让AI自己发明学习规则。

DiscoRL架构图 - 论文Fig.1，展示了AI如何自主发现强化学习规则
具体怎么做的呢？

他们设计了两波AI。一波是「学生AI」，负责玩各种游戏；另一波是「老师AI」（Meta-network），专门观察学生AI的学习过程。

老师AI不玩游戏，它只做一件事：找出什么样的「学习规则」能让学生AI学得更快更好，然后不断改进这个规则。

经过成千上万次迭代，这套由AI自己发明的学习规则（DiscoRL）

打破了Atari游戏测试的历史记录

更关键的是，这套规则不仅在训练用的游戏上表现出色，拿去玩从来没见过的新游戏，它也比人类设计的算法更强。

这才是令人细思极恐的地方

为什么这件事很重要？
过去40年，AI进步的路径是这样的：

1. 第一阶段：人类手把手教AI「看什么」（特征工程时代）
人类告诉AI：这是棋盘的好棋型，这是危险位置。AI能力的上限 = 人类能描述的知识的上限
2. 第二阶段：人类教AI「怎么学」，让它自己提取特征（深度学习时代）
人类不再告诉AI看哪里，但仍然规定学习规则：如果你赢了，就按这个公式加强刚才的动作。AI能力的上限 = 人类能设计的算法的上限。
3. 第三阶段（这篇论文）：AI自己发明「怎么学」
人类从「直接操控」到「只管规则」，再到「连规则都管不了」。

每一次进化的本质都是一样的

人类往后退一步，AI往前进一步。

这篇论文证明的，就是AI已经有能力承接「设计学习规则」这个权力了

有一个细节，特别值得玩味
论文里提到，他们发现的这套算法使用了两组神秘的向量，叫做y和z。

这两个变量没有预定义的含义。

人类不知道它们代表什么。是代表危险？代表机会？代表价值？都不是。

它们不对应任何人类能理解的概念。

但实验证明，AI只要关注这些「莫名其妙」的指标，就能学得比只关注人类定义的「奖励」或「价值」更好。

AI发明了自己的「心理语言」，而这套语言人类看不懂。

这让我想到一个有点恐怖的可能：

未来最高效的智能形式，可能完全不符合人类的逻辑。我们只能看到它在解决问题，却永远无法理解它「在想什么」。

站远一点看：这意味着什么？
如果说AlphaGo的胜利是「在人类设计的规则里打败了人类」

那这篇论文的胜利是「AI证明人类设计的规则太低效了，然后自己发明了更好的」。

这不是量变，是质变。

过去，AI的进步靠的是：DeepMind发论文 → 工程师读论文 → 改代码 → AI变强。

未来的路径可能是：AI做实验 → AI修改自己的底层代码 → AI变强。

人类科学家不再是AI进化的「设计者」，变成了「观察者」

论文的结尾写得非常直白：

「这表明，未来AI算法的设计，可能将由机器来主导，而机器能够利用数据和算力进行有效的扩展。」

我们人类的认知带宽太窄了，还是让AI自己来吧

但是，人类真的准备好了吗？



 

参考来源：

• 论文地址：https://www.nature.com/articles/s41586-025-09761-x
• deepmind项目地址：https://google-deepmind.github.io/disco_rl/
• 代码开源地址：https://github.com/google-deepmind/disco_rl