---
para: archive
domain: 归档
type: 笔记
tags: [洞察, 观点打磨]
layer: 本质
status: archived
summary: AI加剧人际差距：机器流畅度与表达控制能力
created: 2026-02-13
updated: 2026-02-13
reviewed_at: 2026-02-14
---

很多人相信，AI会让世界变得更平等。 当所有人都能用同一个大模型，信息不对称会消失，能力差距会拉平，结果也会越来越趋同。

这是一个很顺滑的故事，但现实情况可能正好相反。

大多数人还沉浸在‘AI 会让世界更公平’的幻想里，少数人已经看到分化正在加速。

一项颠覆直觉的研究

最近读到一篇论文，来自K. Lee和Sanjog Misra团队。他们问了一个很尖锐的问题：

当交易由AI代理来完成时，经济结果会变得更同质化，还是更分化？

结论让人意外：AI Agent执行的交易，产生的结果分散度，竟然比人与人之间的交易更大。

换句话说，如果让机器去谈判、去决策、去执行，不同人 得到的结果「差距更明显」

为什么AI会加剧结果分化？

论文给出了几个发现：

AI放大而非消除个人特质

AI不是在替你思考，而是在放大你的思考。

提示词写得好，AI执行得精准；提示词写得模糊，结果就会偏离你的意图。

研究发现，用户在提示词里带入的那些「非工具性特质」——比如表达习惯、认知偏差、情绪倾向——会直接影响AI的产出。

机器没有消除你的缺陷，它只是把你的缺陷忠实地执行了一遍。 你以为自己在用 AI，其实你只是把自己的偏见放大了 100 倍。

新的竞争力：机器流畅度

一个新的竞争力正在浮现

论文中把这个竞争力叫做 机器流畅度（Machine Fluency）

有些人天生就更会「跟机器说话」。他们能用更清晰的语言描述目标，更精确地约束边界，更有效地引导AI朝自己想要的方向走。

它不是学历，不是智商，也不是你读过多少书。它是一种新的「表达-控制」能力。

而这种能力的分布，在人群中并不均匀。有些人用AI，能把生产力放大10倍；有些人用AI，只是在制造更多的噪音。   你每次写周报前，跟 AI 的那段对话，其实正在决定你的职业差距。

游戏规则的改变

一些人与人交往中的规律，在人机交互里发生了反转。

最典型的例子是性别。在传统的人与人谈判中，男性往往能争取到更好的结果。这背后有很多原因： 社会对「强势」的期待、谈判桌上的气势压制、对方的刻板印象让步…         很多时候男性赢的不是逻辑，是「场」

但AI不吃这套。

机器不会因为你声音洪亮就多让你一成，也不会因为你皱眉就改变报价。它只看一件事：你的提示词写得清不清楚，你的目标表达得准不准确。

论文发现，在某些AI谈判场景中，女性反而取得了更好的结果。

这不是说AI偏向女性，而是当「气势」和「社会压力」这些因素被剥离后，真正起作用的因素变了。

谁更擅长清晰表达需求，谁更愿意细致地打磨指令，谁就更容易从AI那里拿到想要的结果。

机器没有复制人类世界的偏见，但它也没有完全「纠正」什么，它只是创造了一套新的游戏规则。

从信息不对称到心智模型不对称

这篇论文让我想到一个更大的问题：以前我们谈不平等，主要谈的是「信息不对称」

你有信息，我没有；你能接触到资源，我被隔绝在外。

以前获取信息的难度在于 「优质的信息源难获得」现在获取信息的难度在于 「准确表达自己的需求」

你以为你说清楚了，但AI理解的和你想的不一样。

现在用AI，最怕的是「心智不对称」——你以为自己说得很清楚，但AI的理解和你的期待之间，有一道隐形的鸿沟。

而这道鸿沟，不是AI的问题，是你的问题。

工具是平等的，但人不是

所以，回到最初的问题：AI会让世界变得更平等吗？

这篇论文给出的答案是：不一定。甚至可能相反。

工具是平的，但使用工具的人不是AI Agent把「信息差」这个老问题，替换成了一个新问题：

「表达差」和「认知差」。

以前拼的是「你知不知道」现在拼的是「你会不会说」

以前的门槛是「获取」现在的门槛是「驾驭」

论文原文地址：https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5875162

#AI #Inequality #MachineFluency